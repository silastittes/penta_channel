{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stages of file generatation and usage\n",
    "\n",
    "1. initial file by opening, creating empty data sets for markers and channels, storing meta data (file id, anything else?)\n",
    "       - def h5_init(bam_name)\n",
    "\n",
    "2. Write marker info and channels to file -- hopefully auto chunking will be fast and effecient. Assuming it's not too slow, I think writing all loci to file is best, filtering out what sites to use can be decided in subsequent steps. lot a memory potentially.\n",
    "\n",
    "\n",
    "3. construct a common set of loci by inserting empty channels as needed. will need to make choices about filtering at the same stage. this seems like the most challening part (pho king A)\n",
    "\n",
    "\n",
    "\n",
    "unaddressed challenges\n",
    "\n",
    "- need to modify marker names to account for inserts -- perhaps change them to be format: chrom ipos? as in \"A i10\"?\n",
    "\n",
    "- how to effeciently insert empty channels where individuals don't match --- sheesh. this chunk of code may help:\n",
    "\n",
    "penta_ex = make_penta(seq_str, qual_str, depth_str, \"T\", qual_min=0)\n",
    "print(penta_ex)\n",
    "penta_ex = np.insert(penta_ex, obj = [0, 0], values = -999, axis=0)\n",
    "penta_ex.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/silastittes/Dropbox/penta_channel/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_penta(bam_in, h5_out):\n",
    "\n",
    "    with h5py.File(h5_out, 'w') as f:\n",
    "\n",
    "        channels = f.create_dataset('channels', (0, 0), maxshape=(None,None), dtype='f8', chunks=True)\n",
    "        makers = f.create_dataset('markers', (0, 0), maxshape=(None,2), dtype = 'S100', chunks=True)\n",
    "\n",
    "        metadata = {'id': bam_in\n",
    "                   }\n",
    "        f.attrs.update(metadata)\n",
    "        \n",
    "def add_pentas(h5_out, penta_arr, marker_arr):\n",
    "    try:\n",
    "        with h5py.File(h5_out, 'a') as f:\n",
    "            channels = f['channels']\n",
    "            ch_end = channels.shape[0]\n",
    "            \n",
    "            shp = channels.shape[0] + penta_arr.shape[0]\n",
    "            channels.resize((shp, 5))    \n",
    "            channels[ch_end:shp] = penta_arr \n",
    "            \n",
    "            markers = f['markers']\n",
    "            mrk_end = markers.shape[0]\n",
    "            mrk_shp = markers.shape[0] + marker_arr.shape[0]\n",
    "            markers.resize((mrk_shp, 2))\n",
    "            markers[mrk_end:mrk_shp] = marker_arr\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(\"{0} not found\".format(h5_out))\n",
    "\n",
    "        \n",
    "#older version        \n",
    "def make_penta(seq_str, qual_str, depth_str, ref, qual_min = 50):\n",
    "    seq_str = seq_str.upper()\n",
    "    nuc_dict = {\"A\":0, \"T\":1, \"G\":2, \"C\":3, \"*\":4}\n",
    "    nucs = {\"A\": 0, \"T\": 0, \"G\":0, \"C\":0, \"*\":0}\n",
    "\n",
    "    if depth_str == \"0\" and seq_str == \"*\" and qual_str == \"*\":\n",
    "        seq_channel = [[0,0,0,0,0]]\n",
    "        #return np.array(seq_channel)\n",
    "        return seq_channel\n",
    "\n",
    "    else:\n",
    "        i = 0\n",
    "        q = 0\n",
    "        inserts = list()\n",
    "        gaps = list()\n",
    "\n",
    "        while len(seq_str) > i:\n",
    "            if seq_str[i] == \"$\": i += 1\n",
    "            if seq_str[i] == \"^\": i += 2\n",
    "            if seq_str[i] in [\".\", \",\"]:\n",
    "                if ord(qual_str[q]) > qual_min:\n",
    "                    nucs[ref] += 1\n",
    "                q += 1\n",
    "\n",
    "            if seq_str[i] in nucs:\n",
    "                if ord(qual_str[q]) > qual_min:\n",
    "                    nucs[seq_str[i]] += 1\n",
    "                q += 1\n",
    "\n",
    "            if seq_str[i] in [\"+\"]:\n",
    "                i += 1\n",
    "                j = 0\n",
    "                insert_str = \"\"\n",
    "                while seq_str[i].isnumeric():\n",
    "                    insert_str += seq_str[i]\n",
    "                    i += 1\n",
    "                    j += 1\n",
    "                insert_int = int(insert_str)\n",
    "                insert_seq = seq_str[i:i + insert_int]\n",
    "                while len(inserts) < insert_int:\n",
    "                    inserts.append([0,0,0,0,0])\n",
    "\n",
    "                for s in range(len(insert_seq)):\n",
    "                    inserts[s][nuc_dict[insert_seq[s]]] +=1\n",
    "\n",
    "                i += len(insert_str) + insert_int - 2\n",
    "\n",
    "            if seq_str[i] in [\"-\"]:\n",
    "                i += 1\n",
    "                j = 0\n",
    "                gap_str = \"\"\n",
    "                while seq_str[i].isnumeric():\n",
    "                    gap_str += seq_str[i]\n",
    "                    i += 1\n",
    "                    j += 1\n",
    "                gap_int = int(gap_str)\n",
    "\n",
    "                i += len(gap_str) + gap_int - 2\n",
    "            i += 1\n",
    "\n",
    "        seq_channel = list(nucs.values())\n",
    "        inserts.insert(0,seq_channel)\n",
    "        #return np.array(inserts)\n",
    "        return inserts\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #IUFHIUHWIUFHWDF\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#newer version SEEMS TO BE WORKING, BUT MORE TESTS NEEDED!!!\n",
    "def make_penta(seq_str, qual_str, depth_str, ref, qual_min = 50):\n",
    "    seq_str = seq_str.upper()\n",
    "    \n",
    "    nuc_dict = {\"A\":0, \"T\":1, \"G\":2, \"C\":3, \"*\":4, \"N\":5}\n",
    "    nucs = {\"A\": 0, \"T\": 0, \"G\":0, \"C\":0, \"*\":0, \"N\":0}\n",
    "    inserts = {\"A\": 0, \"T\": 0, \"G\":0, \"C\":0, \"*\":0, \"N\":0}\n",
    "    \n",
    "    if depth_str == \"0\" and seq_str == \"*\" and qual_str == \"*\":\n",
    "        seq_channel = [[0,0,0,0,0], [0,0,0,0,0]]\n",
    "        return seq_channel\n",
    "    \n",
    "    else:\n",
    "        i = 0\n",
    "        q = 0\n",
    "        while i < len(seq_str):\n",
    "            if seq_str[i] == \"$\": \n",
    "                i += 1\n",
    "            elif seq_str[i] == \"^\": \n",
    "                i += 2\n",
    "                \n",
    "            elif seq_str[i] in [\".\", \",\"]:\n",
    "                if ord(qual_str[q]) > qual_min:\n",
    "                    nucs[ref] += 1\n",
    "                i += 1\n",
    "                q += 1\n",
    "\n",
    "            elif seq_str[i] in nucs:\n",
    "                if ord(qual_str[q]) > qual_min:\n",
    "                    nucs[seq_str[i]] += 1\n",
    "                i += 1\n",
    "                q += 1\n",
    "\n",
    "                \n",
    "            elif seq_str[i] == \"+\":\n",
    "                i += 1\n",
    "                j = 0\n",
    "                insert_str = \"\"\n",
    "                while seq_str[i].isnumeric():\n",
    "                    insert_str += seq_str[i]\n",
    "                    i += 1\n",
    "                    j += 1\n",
    "                insert_int = int(insert_str)\n",
    "                insert_seq = seq_str[i:i + insert_int]\n",
    "                i += insert_int\n",
    "\n",
    "                for s in range(len(insert_seq)):\n",
    "                    inserts[insert_seq[s]] += 1\n",
    "\n",
    "            elif seq_str[i] == \"-\":\n",
    "                i += 1\n",
    "                j = 0\n",
    "                gap_str = \"\"\n",
    "                while seq_str[i].isnumeric():\n",
    "                    gap_str += seq_str[i]\n",
    "                    i += 1\n",
    "                    j += 1\n",
    "                gap_int = int(gap_str)\n",
    "                i += gap_int\n",
    "                \n",
    "        seq_channel = [list(nucs.values())[0:5], list(inserts.values())[0:5]]\n",
    "        #seq_channel = [list(nucs.values()), list(inserts.values())]\n",
    "        return seq_channel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_penta(\"data/bam/no.bam\", \"data/h5/test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1, 0, 0], [11, 0, 0, 3, 0]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = \"A\"\n",
    "qual_min = 0\n",
    "\n",
    "\n",
    "\n",
    "#seq_str = \"*$.$.$.$.$.$.+5AGACT.+5AGACT.+5AGACT.+5AGACT.+5AGACT,+5agact.+5AGACT.+5AGACT.+5AGACT.+5AGACT.+5AGACT.+5AGACT\"\n",
    "#qual_str = \"221102222222222222\"\n",
    "#depth_str = len(qual_str)\n",
    "\n",
    "#seq_str = \"*\"\n",
    "#qual_str = \"*\"\n",
    "#depth_str = \"0\"\n",
    "\n",
    "seq_str = \",.$.....,*.,.,...,,,.,..^+.\"\n",
    "qual_str = \"<<<22<<<<<<<<<<<2<;<172#\"\n",
    "depth_str = len(qual_str)\n",
    "\n",
    "seq_str = \"*+3AGG**a*G**+3AGG+4TTTT-5gccttcA\"\n",
    "seq_str = \"***a*G+3TTT**cA\"\n",
    "qual_str = \"222222222%\"\n",
    "depth_str = len(qual_str)\n",
    "\n",
    "seq_str = \".G$,+6ACAACC-3CCC-1A^~.+5AAAAA+3AAA-6AAAAAA\"\n",
    "qual_str = \"AAAA\"\n",
    "depth_str = \"4\"\n",
    "\n",
    "\n",
    "#seq_str = \"AA+10ATGC*ATGC*GC\"\n",
    "#qual_str = \"2222\"\n",
    "#depth_str = \"0\"\n",
    "\n",
    "\n",
    "make_penta(seq_str, qual_str, depth_str, ref = \"N\", qual_min=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]] \n",
      " [[b'reference' b'1']\n",
      " [b'reference' b'i1']\n",
      " [b'reference' b'2']\n",
      " ...\n",
      " [b'reference' b'i4999']\n",
      " [b'reference' b'5000']\n",
      " [b'reference' b'i5000']]\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]] \n",
      " [[b'reference' b'i1']\n",
      " [b'reference' b'i2']\n",
      " [b'reference' b'i3']\n",
      " ...\n",
      " [b'reference' b'i4966']\n",
      " [b'reference' b'i4967']\n",
      " [b'reference' b'i4968']]\n",
      "(10000, 5) (4968, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/silastittes/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"src/test.h5\", 'a') as f:\n",
    "    channels = f['channels']\n",
    "    ch = channels[:]  \n",
    "    markers = f['markers']\n",
    "    mrk = markers[:]  \n",
    "print(ch, \"\\n\", mrk)\n",
    "\n",
    "with h5py.File(\"src/test2.h5\", 'a') as f:\n",
    "    channels = f['channels']\n",
    "    ch2 = channels[:]  \n",
    "    markers = f['markers']\n",
    "    mrk = markers[:]  \n",
    "print(ch2, \"\\n\", mrk)\n",
    "\n",
    "np.mean(ch == ch2)\n",
    "print(ch.shape, ch2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = make_penta(seq_str, qual_str, depth_str, ref, qual_min=0)\n",
    "chrom = \"ch\"\n",
    "pos = \"1\"\n",
    "mrk_init = [[chrom, pos]]\n",
    "mrk_init.append([chrom, pos])\n",
    "np.array([[chrom, \"i\"+str(int(pos)+ i)] for i in range(len(c1))], dtype = \"S100\")\n",
    "c1\n",
    "\n",
    "ll = []\n",
    "ll.append(1)\n",
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'notebooks/seqs.fa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1214b8f0ed56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#make_fastas(\"notebooks/seqs.fa\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmake_fastas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"notebooks/seqs.fa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-1214b8f0ed56>\u001b[0m in \u001b[0;36mmake_fastas\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_fastas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'seqs.fa'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mfastas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasta_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"notebooks/seqs.fa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfastas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'seq_{0}.fa'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1214b8f0ed56>\u001b[0m in \u001b[0;36mfasta_dict\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfasta_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"seqs.fa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mseq_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfa\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mln\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfa\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'notebooks/seqs.fa'"
     ]
    }
   ],
   "source": [
    "def fasta_dict(file_name = \"seqs.fa\"):\n",
    "    seq_dict = dict()\n",
    "    with open(file_name) as fa:\n",
    "        for ln in fa:\n",
    "            line = ln.strip()\n",
    "            if line and line[0] == \">\":\n",
    "                seq_name = line[1:]\n",
    "                if seq_name not in seq_dict:\n",
    "                    seq_dict[seq_name] = \"\"\n",
    "                else:\n",
    "                    raise ValueError(\"Fasta headers are not unique.\")\n",
    "            else:\n",
    "                seq_dict[seq_name] += ln.strip()\n",
    "    return seq_dict\n",
    "\n",
    "def make_fastas(file_name = 'seqs.fa'):    \n",
    "    fastas = fasta_dict(\"notebooks/seqs.fa\")\n",
    "    for name, seq in fastas.items():\n",
    "        with open('seq_{0}.fa'.format(name), 'w+') as out_file:\n",
    "            out_file.write(\">reference_{0}\\n{1}\\n\".format(name, seq))\n",
    "        \n",
    "#make_fastas(\"notebooks/seqs.fa\")\n",
    "\n",
    "make_fastas(\"notebooks/seqs.fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr_empty = np.zeros((100,2))\n",
    "np.count_nonzero(arr_empty, axis = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
